{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-Learn: Classification and Regression Models & Examples\n",
    "\n",
    "This notebook will explore various classification and regression techniques available through the scikit-learn python library. The techniques covered in this notebook are:\n",
    "- K-nearest neighbor (KNN)\n",
    "- Support vector machines (SVM)\n",
    "- Decision trees/random forrest\n",
    "- Linear discriminant analysis\n",
    "- Logistic regression\n",
    "\n",
    "The dataset that we will use are the MNIST handwritten digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a number 5\n",
      "\n",
      "\n",
      "(1437, 8, 8)\n",
      "Shapes of our train/test data and labels:\n",
      "\tx_train: (1437, 8, 8)\n",
      "\ty_train: (1437,)\n",
      "\tx_test: (360, 8, 8)\n",
      "\ty_test: (360,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gzip\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "\n",
    "\n",
    "data = datasets.load_digits()\n",
    "images = data.images\n",
    "targets = data.target\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(images, targets, test_size=.2)\n",
    "\n",
    "image = np.asarray(images[5]).squeeze()\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "print(f\"This is a number {targets[5]}\\n\\n\")\n",
    "\n",
    "# Re-shape data so that it's 2D\n",
    "x_train.reshape((1437,64))\n",
    "print(np.shape(x_train))\n",
    "\n",
    "\n",
    "print(f\"Shapes of our train/test data and labels:\")\n",
    "print(f\"\\tx_train: {np.shape(x_train)}\")\n",
    "print(f\"\\ty_train: {np.shape(y_train)}\")\n",
    "print(f\"\\tx_test: {np.shape(x_test)}\")\n",
    "print(f\"\\ty_test: {np.shape(y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest Neighbor Algorithm\n",
    "\n",
    "The nearest neighbor algorithm is one of the more basic classification techniques, and in some cases is actually used as a building block in other richer machine learning algorithms. It's simplicity, in some regard, is where it's power lies: it's fast to implement, and easy to understand. The algorithm looks at the Euclidean distance of given data point to it's nearest neighboring data points to help us gain an understanding of the information contained in the data point of interest. Data points with \"closer\" Euclidean distances are more likely to be similar than ones whose Euclidean distances are quite far. \n",
    "\n",
    "The nearest neighbor algorithm can come in a few different flavors.\n",
    "\n",
    "- **unsupervised**: we don't know the label of any of the neighboring data points\n",
    "\n",
    "- **supervised**: we do know the label of the neighboring data points\n",
    "\n",
    "    - **classification**: the data has a discrete and finite number of values it can take. In supervised nearest neighbor classification, we are typically aiming to predict the class of some data by taking a \"vote\" of the neighboring pixels. Which ever class receives the most votes, we classify our data as such\n",
    "    \n",
    "    - **regression**: the data can take any infinite number of values. In this scenario, we usually take an average of the values of the nearest neighbors\n",
    "    \n",
    "- **radius v.s. k-nearest neighbors**: this determines whether we are looking at a fixed number of neighbors, or all neighbors who are within a fixed distance\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. Estimator expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-e74155c699c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneighbors\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNearestNeighbors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mnbrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNearestNeighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ball_tree'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mdistances\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnbrs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jaked\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m   1162\u001b[0m             \u001b[1;32mor\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'precomputed'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1163\u001b[0m         \"\"\"\n\u001b[1;32m-> 1164\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\jaked\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    398\u001b[0m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_precomputed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 400\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    401\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jaked\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    572\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n\u001b[1;32m--> 574\u001b[1;33m                              % (array.ndim, estimator_name))\n\u001b[0m\u001b[0;32m    575\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    576\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with dim 3. Estimator expected <= 2."
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "nbrs = NearestNeighbors(n_neighbors=2, algorithm='ball_tree').fit(x_train)\n",
    "distances, indices = nbrs.kneighbors(X)\n",
    "indices\n",
    "distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
